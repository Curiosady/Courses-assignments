{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[1,-2,3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все параметры наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# TODO: Implement storing gradients for W and B\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W1\n",
      "Gradient check passed!\n",
      "Checking gradient for b1\n",
      "Gradient check passed!\n",
      "Checking gradient for W2\n",
      "Gradient check passed!\n",
      "Checking gradient for b2\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W1\n",
      "Gradient check passed!\n",
      "Checking gradient for b1\n",
      "Gradient check passed!\n",
      "Checking gradient for W2\n",
      "Gradient check passed!\n",
      "Checking gradient for b2\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss, loss_with_reg)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, implement predict function!\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки\n",
    "\n",
    "Если все реализовано корректно, значение функции ошибки должно уменьшаться с каждой эпохой, пусть и медленно. Не беспокойтесь пока про validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.214333, Train accuracy: 0.226778, val accuracy: 0.234000\n",
      "Loss: 1.953794, Train accuracy: 0.368667, val accuracy: 0.374000\n",
      "Loss: 1.564549, Train accuracy: 0.550333, val accuracy: 0.554000\n",
      "Loss: 1.293905, Train accuracy: 0.643333, val accuracy: 0.627000\n",
      "Loss: 1.150434, Train accuracy: 0.612333, val accuracy: 0.607000\n",
      "Loss: 1.055399, Train accuracy: 0.699000, val accuracy: 0.669000\n",
      "Loss: 0.994558, Train accuracy: 0.672111, val accuracy: 0.639000\n",
      "Loss: 0.931737, Train accuracy: 0.727889, val accuracy: 0.681000\n",
      "Loss: 0.886818, Train accuracy: 0.755444, val accuracy: 0.701000\n",
      "Loss: 0.836016, Train accuracy: 0.757222, val accuracy: 0.704000\n",
      "Loss: 0.791451, Train accuracy: 0.746444, val accuracy: 0.698000\n",
      "Loss: 0.764978, Train accuracy: 0.790333, val accuracy: 0.728000\n",
      "Loss: 0.724166, Train accuracy: 0.781333, val accuracy: 0.712000\n",
      "Loss: 0.703346, Train accuracy: 0.806778, val accuracy: 0.711000\n",
      "Loss: 0.681072, Train accuracy: 0.801889, val accuracy: 0.708000\n",
      "Loss: 0.648698, Train accuracy: 0.810556, val accuracy: 0.715000\n",
      "Loss: 0.620096, Train accuracy: 0.830889, val accuracy: 0.732000\n",
      "Loss: 0.600500, Train accuracy: 0.840556, val accuracy: 0.730000\n",
      "Loss: 0.575511, Train accuracy: 0.813444, val accuracy: 0.711000\n",
      "Loss: 0.568071, Train accuracy: 0.838333, val accuracy: 0.726000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-5)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate = 1e-1)\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down every epoch, even if it's slow\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9a72ff9828>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate_decay=0.99)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-4, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=150, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach training accuracy in 20 epochs\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=20, batch_size=5)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. \n",
    "\n",
    "Добейтесь точности лучше **60%** на validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "\n",
    "learning_rates = 1e-4\n",
    "reg_strength = 1e-3\n",
    "learning_rate_decay = 0.999\n",
    "hidden_layer_size = 128\n",
    "num_epochs = 200\n",
    "batch_size = 64\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = None\n",
    "\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "# TODO find the best hyperparameters to train the network\n",
    "# Don't hesitate to add new values to the arrays above, perform experiments, use any tricks you want\n",
    "# You should expect to get to at least 40% of valudation accuracy\n",
    "# Save loss/train/history of the best classifier to the variables above\n",
    "\n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как обычно, посмотрим, как наша лучшая модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
