{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[1,-2,3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все параметры наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# TODO: Implement storing gradients for W and B\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W1\n",
      "Gradient check passed!\n",
      "Checking gradient for b1\n",
      "Gradient check passed!\n",
      "Checking gradient for W2\n",
      "Gradient check passed!\n",
      "Checking gradient for b2\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W1\n",
      "Gradients are different at (459, 0). Analytic: -0.00000, Numeric: 0.00008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss, loss_with_reg)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, implement predict function!\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки\n",
    "\n",
    "Если все реализовано корректно, значение функции ошибки должно уменьшаться с каждой эпохой, пусть и медленно. Не беспокойтесь пока про validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 44.281535, Train accuracy: 0.230889, val accuracy: 0.252000\n",
      "Loss: 38.702019, Train accuracy: 0.428667, val accuracy: 0.434000\n",
      "Loss: 30.481434, Train accuracy: 0.514444, val accuracy: 0.530000\n",
      "Loss: 25.930411, Train accuracy: 0.604667, val accuracy: 0.587000\n",
      "Loss: 23.011730, Train accuracy: 0.671111, val accuracy: 0.651000\n",
      "Loss: 21.149931, Train accuracy: 0.710889, val accuracy: 0.680000\n",
      "Loss: 19.614827, Train accuracy: 0.713111, val accuracy: 0.682000\n",
      "Loss: 18.539986, Train accuracy: 0.747222, val accuracy: 0.689000\n",
      "Loss: 17.447548, Train accuracy: 0.738556, val accuracy: 0.706000\n",
      "Loss: 16.414229, Train accuracy: 0.755222, val accuracy: 0.704000\n",
      "Loss: 15.900674, Train accuracy: 0.769778, val accuracy: 0.715000\n",
      "Loss: 15.080308, Train accuracy: 0.775000, val accuracy: 0.712000\n",
      "Loss: 14.521735, Train accuracy: 0.787111, val accuracy: 0.713000\n",
      "Loss: 13.988136, Train accuracy: 0.798000, val accuracy: 0.710000\n",
      "Loss: 13.445828, Train accuracy: 0.792000, val accuracy: 0.716000\n",
      "Loss: 12.838571, Train accuracy: 0.798444, val accuracy: 0.706000\n",
      "Loss: 12.409631, Train accuracy: 0.810889, val accuracy: 0.711000\n",
      "Loss: 12.013539, Train accuracy: 0.790889, val accuracy: 0.716000\n",
      "Loss: 11.392509, Train accuracy: 0.839778, val accuracy: 0.736000\n",
      "Loss: 11.003433, Train accuracy: 0.854889, val accuracy: 0.732000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-5)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate = 1e-1)\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down every epoch, even if it's slow\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3744cc35f8>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 44.338234, Train accuracy: 0.238000, val accuracy: 0.254000\n",
      "Loss: 38.983177, Train accuracy: 0.434889, val accuracy: 0.431000\n",
      "Loss: 31.009837, Train accuracy: 0.540556, val accuracy: 0.537000\n",
      "Loss: 25.991741, Train accuracy: 0.640333, val accuracy: 0.623000\n",
      "Loss: 22.795189, Train accuracy: 0.681222, val accuracy: 0.652000\n",
      "Loss: 20.934195, Train accuracy: 0.704778, val accuracy: 0.696000\n",
      "Loss: 19.528754, Train accuracy: 0.728778, val accuracy: 0.709000\n",
      "Loss: 18.264198, Train accuracy: 0.738778, val accuracy: 0.694000\n",
      "Loss: 17.251827, Train accuracy: 0.754556, val accuracy: 0.698000\n",
      "Loss: 16.170509, Train accuracy: 0.774778, val accuracy: 0.723000\n",
      "Loss: 15.147749, Train accuracy: 0.764667, val accuracy: 0.724000\n",
      "Loss: 14.409980, Train accuracy: 0.801889, val accuracy: 0.725000\n",
      "Loss: 13.613377, Train accuracy: 0.801222, val accuracy: 0.713000\n",
      "Loss: 12.962846, Train accuracy: 0.821444, val accuracy: 0.732000\n",
      "Loss: 12.296437, Train accuracy: 0.808556, val accuracy: 0.717000\n",
      "Loss: 11.855794, Train accuracy: 0.839222, val accuracy: 0.752000\n",
      "Loss: 11.322971, Train accuracy: 0.820556, val accuracy: 0.720000\n",
      "Loss: 11.051962, Train accuracy: 0.866556, val accuracy: 0.751000\n",
      "Loss: 10.515392, Train accuracy: 0.855333, val accuracy: 0.723000\n",
      "Loss: 9.995242, Train accuracy: 0.858444, val accuracy: 0.750000\n"
     ]
    }
   ],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-5)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate= 1e-1, learning_rate_decay=0.99)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 44.548358, Train accuracy: 0.197333, val accuracy: 0.206000\n",
      "Loss: 39.814899, Train accuracy: 0.355222, val accuracy: 0.358000\n",
      "Loss: 31.308936, Train accuracy: 0.554000, val accuracy: 0.547000\n",
      "Loss: 25.665921, Train accuracy: 0.609222, val accuracy: 0.590000\n",
      "Loss: 22.533893, Train accuracy: 0.673889, val accuracy: 0.653000\n",
      "Loss: 20.936159, Train accuracy: 0.671222, val accuracy: 0.662000\n",
      "Loss: 19.490325, Train accuracy: 0.727556, val accuracy: 0.678000\n",
      "Loss: 18.053598, Train accuracy: 0.728889, val accuracy: 0.666000\n",
      "Loss: 17.223844, Train accuracy: 0.750222, val accuracy: 0.703000\n",
      "Loss: 16.372134, Train accuracy: 0.773000, val accuracy: 0.697000\n",
      "Loss: 15.384656, Train accuracy: 0.783444, val accuracy: 0.709000\n",
      "Loss: 14.520239, Train accuracy: 0.811667, val accuracy: 0.725000\n",
      "Loss: 13.847337, Train accuracy: 0.829333, val accuracy: 0.728000\n",
      "Loss: 12.983972, Train accuracy: 0.804000, val accuracy: 0.719000\n",
      "Loss: 12.518401, Train accuracy: 0.835000, val accuracy: 0.731000\n",
      "Loss: 12.048469, Train accuracy: 0.829111, val accuracy: 0.744000\n",
      "Loss: 11.479455, Train accuracy: 0.835778, val accuracy: 0.732000\n",
      "Loss: 10.669328, Train accuracy: 0.836111, val accuracy: 0.727000\n",
      "Loss: 10.481025, Train accuracy: 0.869444, val accuracy: 0.763000\n",
      "Loss: 10.102557, Train accuracy: 0.863222, val accuracy: 0.741000\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-5)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-2, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 11.543493, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 11.467804, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 11.414616, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 11.376256, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 11.312835, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 11.228180, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 11.144667, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 10.913068, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 10.594115, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 9.946964, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 9.388802, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 8.935017, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 8.896434, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 8.289398, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 8.114202, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 8.022371, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 7.752009, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 7.725808, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 7.461885, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 7.340891, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 6.986910, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 6.810799, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 6.562928, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 6.376349, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 5.939696, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 5.790095, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 5.566800, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 5.450697, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 5.459505, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 5.235696, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 4.849833, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 4.525030, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 4.291042, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 4.102038, Train accuracy: 0.800000, val accuracy: 0.133333\n",
      "Loss: 3.984619, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 3.700238, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 3.394686, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 3.249400, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 3.135444, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 2.899941, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 2.816034, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 2.678624, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 2.559784, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 2.482768, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 2.335386, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 2.243496, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 2.142739, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.991834, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.831443, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.709558, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.585510, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.419484, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.255423, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.128971, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.989829, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.875278, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.786393, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.692366, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.607132, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.535770, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.482854, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.429015, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.397478, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.356081, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.332127, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.303281, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.286515, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.264840, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.247283, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.232766, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.217101, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.203803, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.193703, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.183629, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.174853, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.165694, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.157095, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.150412, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.143719, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.138391, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.131292, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.126765, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.122973, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.116824, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.113388, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.109197, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.105102, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.102247, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.098301, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.095511, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.092288, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.089772, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.086862, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.084879, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.082322, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.079986, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.077868, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.075940, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.073961, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.071977, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.070243, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.068545, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.066985, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.065246, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.063798, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.062323, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.061070, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.059515, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.058294, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.056908, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.055960, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.054757, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.053637, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.052575, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.051632, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.050803, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.049749, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.048708, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.047833, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.047209, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.046351, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.045475, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.044521, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.043891, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.043120, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.042491, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.041707, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.041098, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.040379, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.039686, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.039215, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.038613, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.038105, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.037521, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.036930, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.036280, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.035836, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.035256, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.034821, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.034276, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.033847, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.033450, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.032950, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.032504, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.032052, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.031643, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.031292, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.030867, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.030490, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.030144, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-10)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=150, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 17.278099, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 17.080763, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 16.920142, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 16.475482, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 15.318301, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 14.999814, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 13.332952, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 13.593204, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 10.988697, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 16.426625, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 16.487646, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 17.879945, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 32.487309, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 10.284582, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 8.114389, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 8.067853, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 4.803585, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 3.861743, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 3.106521, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 2.416368, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-10)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach training accuracy in 20 epochs\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=0.4, num_epochs=20, batch_size=9)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. \n",
    "\n",
    "Добейтесь точности лучше **60%** на validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 561.824235, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 552.841830, Train accuracy: 0.198000, val accuracy: 0.207000\n",
      "Loss: 511.587924, Train accuracy: 0.317333, val accuracy: 0.317000\n",
      "Loss: 435.145829, Train accuracy: 0.467111, val accuracy: 0.462000\n",
      "Loss: 367.877462, Train accuracy: 0.551333, val accuracy: 0.536000\n",
      "Loss: 322.439479, Train accuracy: 0.613111, val accuracy: 0.605000\n",
      "Loss: 289.018759, Train accuracy: 0.671111, val accuracy: 0.655000\n",
      "Loss: 261.468161, Train accuracy: 0.685778, val accuracy: 0.655000\n",
      "Loss: 242.489222, Train accuracy: 0.703444, val accuracy: 0.696000\n",
      "Loss: 236.002532, Train accuracy: 0.731000, val accuracy: 0.694000\n",
      "Loss: 225.436439, Train accuracy: 0.734111, val accuracy: 0.701000\n",
      "Loss: 211.488385, Train accuracy: 0.751222, val accuracy: 0.703000\n",
      "Loss: 196.836538, Train accuracy: 0.774667, val accuracy: 0.714000\n",
      "Loss: 189.018456, Train accuracy: 0.756667, val accuracy: 0.714000\n",
      "Loss: 185.008720, Train accuracy: 0.793556, val accuracy: 0.728000\n",
      "Loss: 171.651390, Train accuracy: 0.797444, val accuracy: 0.723000\n",
      "Loss: 173.711107, Train accuracy: 0.811111, val accuracy: 0.732000\n",
      "Loss: 165.595553, Train accuracy: 0.808889, val accuracy: 0.719000\n",
      "Loss: 158.309880, Train accuracy: 0.820667, val accuracy: 0.736000\n",
      "Loss: 151.288522, Train accuracy: 0.827444, val accuracy: 0.727000\n",
      "Loss: 147.172634, Train accuracy: 0.831444, val accuracy: 0.744000\n",
      "Loss: 144.169912, Train accuracy: 0.852222, val accuracy: 0.748000\n",
      "Loss: 138.212097, Train accuracy: 0.841778, val accuracy: 0.740000\n",
      "Loss: 136.213995, Train accuracy: 0.861444, val accuracy: 0.770000\n",
      "Loss: 129.624825, Train accuracy: 0.860444, val accuracy: 0.755000\n",
      "Loss: 127.571669, Train accuracy: 0.867333, val accuracy: 0.755000\n",
      "Loss: 124.885332, Train accuracy: 0.865111, val accuracy: 0.761000\n",
      "Loss: 122.247420, Train accuracy: 0.874556, val accuracy: 0.759000\n",
      "Loss: 120.504597, Train accuracy: 0.870556, val accuracy: 0.759000\n",
      "Loss: 116.494828, Train accuracy: 0.877333, val accuracy: 0.748000\n",
      "Loss: 114.513041, Train accuracy: 0.876556, val accuracy: 0.757000\n",
      "Loss: 112.923457, Train accuracy: 0.885778, val accuracy: 0.765000\n",
      "Loss: 110.040529, Train accuracy: 0.891111, val accuracy: 0.759000\n",
      "Loss: 107.333328, Train accuracy: 0.891000, val accuracy: 0.759000\n",
      "Loss: 106.289166, Train accuracy: 0.896889, val accuracy: 0.757000\n",
      "Loss: 105.645225, Train accuracy: 0.894667, val accuracy: 0.763000\n",
      "Loss: 102.219928, Train accuracy: 0.901667, val accuracy: 0.758000\n",
      "Loss: 100.815744, Train accuracy: 0.898000, val accuracy: 0.762000\n",
      "Loss: 98.999527, Train accuracy: 0.903667, val accuracy: 0.760000\n",
      "Loss: 98.396284, Train accuracy: 0.902222, val accuracy: 0.767000\n",
      "Loss: 98.337877, Train accuracy: 0.905000, val accuracy: 0.763000\n",
      "Loss: 95.250790, Train accuracy: 0.906667, val accuracy: 0.758000\n",
      "Loss: 94.586111, Train accuracy: 0.912000, val accuracy: 0.770000\n",
      "Loss: 94.688471, Train accuracy: 0.910000, val accuracy: 0.761000\n",
      "Loss: 92.496838, Train accuracy: 0.912222, val accuracy: 0.769000\n",
      "Loss: 91.358469, Train accuracy: 0.915667, val accuracy: 0.766000\n",
      "Loss: 90.851727, Train accuracy: 0.914111, val accuracy: 0.768000\n",
      "Loss: 90.076701, Train accuracy: 0.916778, val accuracy: 0.768000\n",
      "Loss: 89.722517, Train accuracy: 0.913333, val accuracy: 0.770000\n",
      "Loss: 90.457013, Train accuracy: 0.916000, val accuracy: 0.775000\n",
      "Loss: 88.636462, Train accuracy: 0.918222, val accuracy: 0.769000\n",
      "Loss: 87.559639, Train accuracy: 0.919556, val accuracy: 0.775000\n",
      "Loss: 87.162518, Train accuracy: 0.921778, val accuracy: 0.766000\n",
      "Loss: 86.372626, Train accuracy: 0.922222, val accuracy: 0.767000\n",
      "Loss: 86.467762, Train accuracy: 0.920333, val accuracy: 0.773000\n",
      "Loss: 85.490023, Train accuracy: 0.923778, val accuracy: 0.769000\n",
      "Loss: 84.891369, Train accuracy: 0.922667, val accuracy: 0.771000\n",
      "Loss: 84.602650, Train accuracy: 0.925111, val accuracy: 0.771000\n",
      "Loss: 83.957343, Train accuracy: 0.923333, val accuracy: 0.773000\n",
      "Loss: 83.649712, Train accuracy: 0.925667, val accuracy: 0.767000\n",
      "Loss: 83.262984, Train accuracy: 0.926111, val accuracy: 0.771000\n",
      "Loss: 82.956996, Train accuracy: 0.926667, val accuracy: 0.768000\n",
      "Loss: 82.522421, Train accuracy: 0.926444, val accuracy: 0.770000\n",
      "Loss: 82.246337, Train accuracy: 0.926000, val accuracy: 0.770000\n",
      "Loss: 82.014012, Train accuracy: 0.926778, val accuracy: 0.773000\n",
      "Loss: 81.617096, Train accuracy: 0.925333, val accuracy: 0.770000\n",
      "Loss: 81.738024, Train accuracy: 0.928667, val accuracy: 0.771000\n",
      "Loss: 81.387533, Train accuracy: 0.929000, val accuracy: 0.770000\n",
      "Loss: 81.148299, Train accuracy: 0.927000, val accuracy: 0.770000\n",
      "Loss: 80.763182, Train accuracy: 0.928556, val accuracy: 0.771000\n",
      "Loss: 80.545281, Train accuracy: 0.928222, val accuracy: 0.770000\n",
      "Loss: 80.456311, Train accuracy: 0.929000, val accuracy: 0.772000\n",
      "Loss: 80.257648, Train accuracy: 0.930111, val accuracy: 0.773000\n",
      "Loss: 80.032638, Train accuracy: 0.930000, val accuracy: 0.772000\n",
      "Loss: 79.947347, Train accuracy: 0.930222, val accuracy: 0.772000\n",
      "Loss: 79.569593, Train accuracy: 0.929667, val accuracy: 0.775000\n",
      "Loss: 79.590206, Train accuracy: 0.930889, val accuracy: 0.774000\n",
      "Loss: 79.280564, Train accuracy: 0.930444, val accuracy: 0.774000\n",
      "Loss: 79.259477, Train accuracy: 0.930667, val accuracy: 0.772000\n",
      "Loss: 79.214453, Train accuracy: 0.931111, val accuracy: 0.775000\n",
      "Loss: 78.998071, Train accuracy: 0.928667, val accuracy: 0.770000\n",
      "Loss: 78.966661, Train accuracy: 0.931889, val accuracy: 0.775000\n",
      "Loss: 78.780033, Train accuracy: 0.931667, val accuracy: 0.772000\n",
      "Loss: 78.644256, Train accuracy: 0.931000, val accuracy: 0.772000\n",
      "Loss: 78.503261, Train accuracy: 0.931222, val accuracy: 0.771000\n",
      "Loss: 78.544180, Train accuracy: 0.932000, val accuracy: 0.772000\n",
      "Loss: 78.413208, Train accuracy: 0.931778, val accuracy: 0.772000\n",
      "Loss: 78.315144, Train accuracy: 0.932000, val accuracy: 0.772000\n",
      "Loss: 78.233018, Train accuracy: 0.931667, val accuracy: 0.771000\n",
      "Loss: 78.181614, Train accuracy: 0.931889, val accuracy: 0.773000\n",
      "Loss: 78.053947, Train accuracy: 0.932111, val accuracy: 0.773000\n",
      "Loss: 77.988899, Train accuracy: 0.932222, val accuracy: 0.773000\n",
      "Loss: 77.879973, Train accuracy: 0.932222, val accuracy: 0.771000\n",
      "Loss: 77.873504, Train accuracy: 0.931889, val accuracy: 0.772000\n",
      "Loss: 77.778815, Train accuracy: 0.932111, val accuracy: 0.772000\n",
      "Loss: 77.738356, Train accuracy: 0.932444, val accuracy: 0.773000\n",
      "Loss: 77.702681, Train accuracy: 0.931889, val accuracy: 0.774000\n",
      "Loss: 77.649478, Train accuracy: 0.932333, val accuracy: 0.772000\n",
      "Loss: 77.575841, Train accuracy: 0.932556, val accuracy: 0.772000\n",
      "Loss: 77.539786, Train accuracy: 0.932111, val accuracy: 0.772000\n",
      "best validation accuracy achieved: 0.775000\n"
     ]
    }
   ],
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "\n",
    "learning_rates = 1e-4\n",
    "reg_strength = 1e-3\n",
    "learning_rate_decay = 0.999\n",
    "hidden_layer_size = 128\n",
    "num_epochs = 200\n",
    "batch_size = 64\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = None\n",
    "\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "# TODO find the best hyperparameters to train the network\n",
    "# Don't hesitate to add new values to the arrays above, perform experiments, use any tricks you want\n",
    "# You should expect to get to at least 40% of valudation accuracy\n",
    "# Save loss/train/history of the best classifier to the variables above\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 200, reg = 4e-4)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-1,\\\n",
    "                  learning_rate_decay=0.95, num_epochs=100, batch_size=256)\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "best_val_accuracy = max(val_history)\n",
    "best_classifier = model\n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3734ad4908>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как обычно, посмотрим, как наша лучшая модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural net test set accuracy: 0.748000\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
